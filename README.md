# Hackathon de Engenharia de Dados - A3 Data Challenge Women

<p align="center">
<img src="https://github.com/elladarte/thedatagirl_hackathon/blob/main/images/logo_hackathon.png" alt="Image" height="400" width="800"/>
</p>

## Equipe The Data Girls

<p align="center">
<img src="https://github.com/elladarte/thedatagirl_hackathon/blob/main/images/the_data_girls.png" alt="Image" height="200"/>
</p>

Participantes:
- Rafaella Duarte
- Carolina Dias

### üü£ [Pitch da Solu√ß√£o (2 minutos)](https://youtu.be/bd6tAhl_dVQ)
### üü£ [Demonstra√ßao da Solu√ß√£o (5 minutos)]()
### üü£ [Dashboard com as Respostas](https://datastudio.google.com/u/0/reporting/e24cf11b-9f7d-45ae-864e-807b0b874004/page/p_v4vb5pcunc)


## Desafio
>>>>>>> cc42c5a71770e52a0615123244464acb010021c9

-  Os  times  devem  implementar  pipeline  de  extra√ß√£o,  transforma√ß√£o  e  disponibiliza√ß√£o  de  dados.  Ap√≥s  extra√ß√£o,  limpeza, organiza√ß√£o e estrutura√ß√£o dos dados, as perguntas  chave do desafio devem ser respondidas de maneira visual;
- Fonte: Base CNPJ (Dado de 2010 a junho-2021);
- Livre utiliza√ß√£o de ferramentas para compor a solu√ß√£o.

## Tabela de conte√∫dos
<!--ts-->
* [O Desafio](#desafio)
* [Tabela de Conteudo](#tabela-de-conteudo)
* [Perguntas Chaves](#perguntas-chaves)
* [Avalia√ß√£o](#avalia√ß√£o)
* [Solu√ß√£o](#solu√ß√£o)
    * [Arquitetura](#arquitetura)
    * [Extra√ß√£o dos dados](#extra√ß√£o-dos-dados)
    * [Tratamento e Analise dos dados](#tratamento-e-analise-dos-dados)
    * [Visualiza√ß√£o dos dados](#visualiza√ß√£o-dos-dados)
<!--te-->

## Perguntas Chave

1. N√∫mero de ind√∫strias ativas por m√™s/ano entre 2010 - 2021, discriminado por MEI ou Simples, em cada munic√≠pio brasileiro.
2. N√∫mero de com√©rcios que fecharam por m√™s/ano entre 2010 - 2021, discriminado por MEI ou Simples, em cada munic√≠pio brasileiro.
3. N√∫mero de CNPJ novos por m√™s/ano entre 2010 - 2021, discriminado por MEI ou Simples, em cada munic√≠pio brasileiro.
4. Qual o n√∫mero de CNPJ que surgiram do grupo de educa√ß√£o superior, entre 2015 e 2021, discriminado por ano, em cada estado brasileiro?
5. Qual a classe de CNAE com o maior capital social m√©dio no Brasil no √∫ltimo ano?
6. Qual a m√©dia do capital social das empresas de pequeno porte por natureza  jur√≠dica no √∫ltimo ano?

## Avalia√ß√£o

As solu√ß√µes ser√£o avaliadas pelos mentores de acordo com os  seguintes crit√©rios:
- Escalabilidade;
- Confiabilidade;
- Facilidade de integra√ß√£o em Produ√ß√£o;
- Efici√™ncia Operacional;
- Otimiza√ß√£o de Custos.

## Solu√ß√£o

###Arquitetura
>>>>>>> cc42c5a71770e52a0615123244464acb010021c9

Foi utilizado o ecossistema do Google para a solu√ß√£o desse problema, em particular a Google Cloud Storage (GCP) e o Google Data Studio. Os motivos para a escolha dessas ferramentas s√£o a facilidade de uso e integra√ß√£o total entre todas as ferramentas, al√©m do baixo custo. Al√©m disso, para contas novas h√° um b√¥nus de 300 d√≥lares em cr√©ditos, influenciando mais ainda a decis√£o de escolha desse servi√ßo como um todo.

Na GCP foram utilizados os seguintes servi√ßos:
- Google Cloud Engine Computing para rodar os c√≥digos.
- Google Cloud Storage para o armazenamento dos dados.
- Google BigQuery para a an√°lise dos dados.
O Google Data Studio foi utilizado para as visualiza√ß√µes dos dados.

<p align="center">
<<<<<<< HEAD
<img src="https://github.com/elladarte/thedatagirl_hackathon/blob/main/images/arquitetura.png" alt="Image" height="400" width="600"/>
</p>

- Extra√ß√£o dos dados

Os dados foram extraidos por meio de um scraper que percorre a pagina da Receita Federal, baixamos os arquivos zip e em seguida extraimos os arquivos csv para o Google Cloud Storage. Decidimos enviar para a cloud os dados brutos, para nao ser necessario refazer a coleta para o tratamento dos dados, assim economizando capacidade computacional e tempo.

Script automatizado responsavel: 
    run_storage.py

- Tratamento e Analise dos dados

Para economizar poder computacional, preferimos realizar o tratamento e a analise de dados no Google BigQuery. Desta forma, realizamos a carga dos arquivos csv brutos existentes no Google Cloud Storage, enviando cada um deles para suas respectivas tabelas, de acordo com o schema criado.

<p align="center">
<img src="https://github.com/elladarte/thedatagirl_hackathon/blob/main/images/diagrama_DB.png" alt="Image" height="400" width="600"/>
</p>

Apos a carga das tabelas no Google BigQuery, criamos uma tabela unica com jun√ß√£o das informa√ß√µes das empresas, estabelecimentos, e socios pelo cnpj basico, alem de combinar as colunas com chaves estrangeiras das tabelas de dominio (municipio, pais, motivo, atua√ß√£o juridica, qualifica√ß√£o do socio e cnae), para facilitar a cria√ß√£o das tabelas utilizadas para a visualiza√ß√£o. 

Script automatizado responsavel:
    run_bigquery.py

- Visualiza√ß√£o dos dados


